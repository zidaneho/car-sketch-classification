{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4281c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'download_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdownload_data\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'download_data'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_categories = [\n",
    "    'ambulance', 'bulldozer', 'bus', 'car', 'firetruck', 'pickup truck', \n",
    "    'police car', 'school bus', 'tractor', 'truck', 'van'\n",
    "]\n",
    "not_car_categories = [\n",
    "    'aircraft carrier', 'airplane', 'alarm clock', 'angel', 'animal migration', \n",
    "    'ant', 'anvil', 'apple', 'arm', 'asparagus', 'axe', 'backpack', 'banana', \n",
    "    'bandage', 'barn', 'baseball', 'baseball bat', 'basket', 'basketball', \n",
    "    'bat', 'bathtub', 'beach', 'bear', 'beard', 'bed', 'bee', 'belt', 'bench', \n",
    "    'bicycle', 'binoculars', 'bird', 'birthday cake', 'blackberry', 'blueberry', \n",
    "    'book', 'boomerang', 'bottlecap', 'bowtie', 'bracelet', 'brain', 'bread', \n",
    "    'bridge', 'broccoli', 'broom', 'bucket', 'bush', 'butterfly', 'cactus', \n",
    "    'cake', 'calculator', 'calendar', 'camel', 'camera', 'camouflage', \n",
    "    'campfire', 'candle', 'cannon', 'canoe', 'carrot', 'castle', 'cat', \n",
    "    'ceiling fan', 'cello', 'cell phone', 'chair', 'chandelier', 'church', \n",
    "    'circle', 'clarinet', 'clock', 'cloud', 'coffee cup', 'compass', 'computer', \n",
    "    'cookie', 'cooler', 'couch', 'cow', 'crab', 'crayon', 'crocodile', 'crown', \n",
    "    'cruise ship', 'cup', 'diamond', 'dishwasher', 'diving board', 'dog', \n",
    "    'dolphin', 'donut', 'door', 'dragon', 'dresser', 'drill', 'drums', 'duck', \n",
    "    'dumbbell', 'ear', 'elbow', 'elephant', 'envelope', 'eraser', 'eye', \n",
    "    'eyeglasses', 'face', 'fan', 'feather', 'fence', 'finger', 'fire hydrant', \n",
    "    'fireplace', 'fish', 'flamingo', 'flashlight', 'flip flops', 'floor lamp', \n",
    "    'flower', 'flying saucer', 'foot', 'fork', 'frog', 'frying pan', 'garden', \n",
    "    'garden hose', 'giraffe', 'goatee', 'golf club', 'grapes', 'grass', \n",
    "    'guitar', 'hamburger', 'hammer', 'hand', 'harp', 'hat', 'headphones', \n",
    "    'hedgehog', 'helicopter', 'helmet', 'hexagon', 'hockey puck', \n",
    "    'hockey stick', 'horse', 'hospital', 'hot air balloon', 'hot dog', \n",
    "    'hot tub', 'hourglass', 'house', 'house plant', 'hurricane', 'ice cream', \n",
    "    'jacket', 'jail', 'kangaroo', 'key', 'keyboard', 'knee', 'knife', 'ladder', \n",
    "    'lantern', 'laptop', 'leaf', 'leg', 'light bulb', 'lighter', 'lighthouse', \n",
    "    'lightning', 'line', 'lion', 'lipstick', 'lobster', 'lollipop', 'mailbox', \n",
    "    'map', 'marker', 'matches', 'megaphone', 'mermaid', 'microphone', \n",
    "    'microwave', 'monkey', 'moon', 'mosquito', 'motorbike', 'mountain', \n",
    "    'mouse', 'moustache', 'mouth', 'mug', 'mushroom', 'nail', 'necklace', \n",
    "    'nose', 'ocean', 'octagon', 'octopus', 'onion', 'oven', 'owl', \n",
    "    'paintbrush', 'paint can', 'palm tree', 'panda', 'pants', 'paper clip', \n",
    "    'parachute', 'parrot', 'passport', 'peanut', 'pear', 'peas', 'pencil', \n",
    "    'penguin', 'piano', 'picture frame', 'pig', 'pillow', 'pineapple', 'pizza', \n",
    "    'pliers', 'pond', 'pool', 'popsicle', 'postcard', 'potato', 'power outlet', \n",
    "    'purse', 'rabbit', 'raccoon', 'radio', 'rain', 'rainbow', 'rake', \n",
    "    'remote control', 'rhinoceros', 'rifle', 'river', 'roller coaster', \n",
    "    'rollerskates', 'sailboat', 'sandwich', 'saw', 'saxophone', 'scissors', \n",
    "    'scorpion', 'screwdriver', 'sea turtle', 'see saw', 'shark', 'sheep', \n",
    "    'shoe', 'shorts', 'shovel', 'sink', 'skateboard', 'skull', 'skyscraper', \n",
    "    'sleeping bag', 'smiley face', 'snail', 'snake', 'snorkel', 'snowflake', \n",
    "    'snowman', 'soccer ball', 'sock', 'speedboat', 'spider', 'spoon', \n",
    "    'spreadsheet', 'square', 'squiggle', 'squirrel', 'stairs', 'star', \n",
    "    'steak', 'stereo', 'stethoscope', 'stitches', 'stop sign', 'stove', \n",
    "    'strawberry', 'streetlight', 'string bean', 'submarine', 'suitcase', \n",
    "    'sun', 'swan', 'sweater', 'swing set', 'sword', 'syringe', 'table', \n",
    "    'teapot', 'teddy-bear', 'telephone', 'television', 'tennis racquet', \n",
    "    'tent', 'The Eiffel Tower', 'The Great Wall of China', 'The Mona Lisa', \n",
    "    'tiger', 'toaster', 'toe', 'toilet', 'tooth', 'toothbrush', 'toothpaste', \n",
    "    'tornado', 'traffic light', 'train', 'tree', 'triangle', 'trombone', \n",
    "    'trumpet', 't-shirt', 'umbrella', 'underwear', 'vase', 'violin', \n",
    "    'washing machine', 'watermelon', 'waterslide', 'whale', 'wheel', \n",
    "    'windmill', 'wine bottle', 'wine glass', 'wristwatch', 'yoga', 'zebra', \n",
    "    'zigzag'\n",
    "]\n",
    "all_categories = car_categories + not_car_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6699625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car: (182764, 784)\n",
      "Apple: (144722, 784)\n",
      "Cloud: (120265, 784)\n",
      "Tree: (144721, 784)\n",
      "Truck: (131354, 784)\n",
      "Van: (165909, 784)\n"
     ]
    }
   ],
   "source": [
    "car_data = []\n",
    "not_car_data = []\n",
    "\n",
    "for category in car_categories:\n",
    "    path = os.path.join('data',f\"{category}.npy\")\n",
    "    if os.path.exists(path):\n",
    "        data = np.load(f'data/{category}.npy')\n",
    "        if (data):\n",
    "            car_data.append(data)\n",
    "for category in not_car_categories:\n",
    "    path = os.path.join('data',f\"{category}.npy\")\n",
    "    if os.path.exists(path):\n",
    "        data = np.load(f'data/{category}.npy')\n",
    "        if (data):\n",
    "            not_car_data.append(data)\n",
    "\n",
    "car_data = np.load(\"data/car.npy\")\n",
    "apple_data = np.load(\"data/apple.npy\")\n",
    "cloud_data = np.load(\"data/cloud.npy\")\n",
    "tree_data = np.load(\"data/tree.npy\")\n",
    "truck_data = np.load(\"data/truck.npy\")\n",
    "van_data = np.load(\"data/van.npy\")\n",
    "\n",
    "print(\"Car:\",car_data.shape)\n",
    "print(\"Apple:\",apple_data.shape)\n",
    "print(\"Cloud:\",cloud_data.shape)\n",
    "print(\"Tree:\",tree_data.shape)\n",
    "print(\"Truck:\",truck_data.shape)\n",
    "print(\"Van:\",van_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape : (889735, 784)\n",
      "Final labels: (889735,)\n"
     ]
    }
   ],
   "source": [
    "X_cars = np.concatenate(car_data, axis=0)\n",
    "X_not_cars = np.concatenate(not_car_data, axis=0)\n",
    "\n",
    "y_cars = np.ones(X_cars.shape[0])\n",
    "y_not_cars = np.zeros(X_not_cars.shape[0])\n",
    "\n",
    "X = np.concatenate([X_cars,X_not_cars],axis=0)\n",
    "y = np.concatenate([y_cars,y_not_cars],axis=0)\n",
    "\n",
    "print(\"Final shape :\",X.shape)\n",
    "print(\"Final labels:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843ae019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: (711788, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.permutation(len(X))\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# 1. Reshape from flattened (889735, 784) to (889735, 28, 28)\n",
    "X_train_reshaped = X_train.reshape(-1, 28, 28)\n",
    "X_test_reshaped = X_test.reshape(-1, 28, 28)\n",
    "\n",
    "# 2. Add the channel dimension and repeat it 3 times to simulate RGB\n",
    "# This results in a shape of (samples, 28, 28, 3)\n",
    "X_train_rgb = np.repeat(X_train_reshaped[:, :, :, np.newaxis], 3, axis=-1)\n",
    "X_test_rgb = np.repeat(X_test_reshaped[:, :, :, np.newaxis], 3, axis=-1)\n",
    "\n",
    "print(\"New shape:\", X_train_rgb.shape) \n",
    "# Output will be (samples, 28, 28, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f9d9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Reshape to 28x28 and normalize to [0, 1]\n",
    "        img = self.images[idx].reshape(28, 28).astype(np.float32) / 255.0\n",
    "        # 2. Convert to 3 channels (RGB) by repeating\n",
    "        img = np.stack([img] * 3, axis=0) # Shape: (3, 28, 28)\n",
    "        \n",
    "        image_tensor = torch.from_numpy(img)\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image_tensor)\n",
    "            \n",
    "        return image_tensor, label_tensor\n",
    "    \n",
    "# Transformations: Resize to 32x32 as in your Keras code\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32), antialias=True)\n",
    "])\n",
    "\n",
    "# Create Loaders\n",
    "train_dataset = SketchDataset(X_train, y_train, transform=data_transforms)\n",
    "test_dataset = SketchDataset(X_test, y_test, transform=data_transforms)\n",
    "\n",
    "# Create a 10% validation split from training data\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(train_dataset)), test_size=0.1, stratify=y_train\n",
    ")\n",
    "train_loader = DataLoader(Subset(train_dataset, train_idx), batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(Subset(train_dataset, val_idx), batch_size=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a57bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /Users/zidaneho/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 27.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze the base model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the classifier head\n",
    "# Keras: Dense(128, ReLU) -> Dropout(0.2) -> Dense(1, Sigmoid)\n",
    "num_ftrs = model.last_channel # 1280\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55863801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.2188\n",
      "Epoch 2/3, Loss: 0.1886\n",
      "Epoch 3/3, Loss: 0.1811\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# Run for 3 epochs\n",
    "for epoch in range(3):\n",
    "    loss = train_one_epoch()\n",
    "    print(f\"Epoch {epoch+1}/3, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "041d9dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 93.97%\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return (correct / total) * 100\n",
    "\n",
    "test_acc = check_accuracy(test_loader)\n",
    "print(f\"Final Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "PATH = \"model_data/car_sketch_weights.pth\"\n",
    "\n",
    "torch.save(model.state_dict(),PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-comp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
